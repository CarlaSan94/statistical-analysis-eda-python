{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQDO4JCqTThV"
      },
      "source": [
        "\n",
        "# Exploratory Data Analysis – Customer Churn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Objective\n",
        "#The objective of this analysis is to explore customer churn data in order to identify patterns, trends, and variables potentially associated with customer retention and churn."
      ],
      "metadata": {
        "id": "PwxN3jhBPJQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGyDovL2QDLa"
      },
      "source": [
        "## Data Loading and Initial Inspection\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "df = pd.read_csv(\"../data/churn_dataset.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oVZnezwQ159"
      },
      "source": [
        "df.info()\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbKQ0noRptD"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "# 1) Drop irrelevant columns (only if clearly identifiers or empty)\n",
        "cols_to_drop = [\"Column_1\", \"Column_2\"]  # e.g., IDs, unnamed index columns\n",
        "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors=\"ignore\")\n",
        "\n",
        "# 2) Standardize column names\n",
        "rename_map = {\"Column_1\": \"C1\", \"Column_2\": \"C2\"}\n",
        "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
        "\n",
        "# 3) Remove duplicates\n",
        "n_before = len(df)\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Removed duplicates: {n_before - len(df)}\")\n",
        "\n",
        "# 4) Missing values\n",
        "missing = df.isna().mean().sort_values(ascending=False)\n",
        "display(missing.head(15))\n",
        "\n",
        "# Example strategy:\n",
        "# - drop rows only if target is missing (replace 'Churn' with your target)\n",
        "target_col = \"Churn\"\n",
        "if target_col in df.columns:\n",
        "    n_before = len(df)\n",
        "    df = df.dropna(subset=[target_col])\n",
        "    print(f\"Dropped rows with missing target: {n_before - len(df)}\")\n",
        "\n",
        "# - for numerical columns: impute with median (simple, robust baseline)\n",
        "num_cols = df.select_dtypes(include=\"number\").columns\n",
        "df[num_cols] = df[num_cols].apply(lambda s: s.fillna(s.median()))\n",
        "\n",
        "# - for categorical columns: impute with mode\n",
        "cat_cols = df.select_dtypes(exclude=\"number\").columns\n",
        "for c in cat_cols:\n",
        "    if df[c].isna().any():\n",
        "        df[c] = df[c].fillna(df[c].mode().iloc[0])\n",
        "\n",
        "# 5) Type conversions\n",
        "# df[\"C3\"] = pd.to_numeric(df[\"C3\"], errors=\"coerce\")\n",
        "\n",
        "# 6) Outliers (IQR method) — apply per feature\n",
        "def iqr_filter(dataframe, col, k=1.5):\n",
        "    q1 = dataframe[col].quantile(0.25)\n",
        "    q3 = dataframe[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - k * iqr\n",
        "    upper = q3 + k * iqr\n",
        "    return dataframe[(dataframe[col] >= lower) & (dataframe[col] <= upper)]\n",
        "\n",
        "# Choose only the columns where outliers are truly problematic\n",
        "outlier_cols = [c for c in [\"Price\"] if c in df.columns]\n",
        "\n",
        "n_before = len(df)\n",
        "for col in outlier_cols:\n",
        "    df = iqr_filter(df, col, k=1.5)\n",
        "print(f\"Removed rows due to outliers: {n_before - len(df)}\")\n",
        "\n",
        "print(\"Final shape:\", df.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Outlier Identification (IQR Method – Flagging, Not Removal)\n",
        "\n",
        "#Outliers are identified using the Interquartile Range (IQR) method and **flagged rather than removed**. This approach preserves potentially meaningful extreme observations (e.g. high-value customers), while still allowing their impact to be analyzed explicitly in subsequent steps.\n",
        "\n",
        "def iqr_flags(s, k=1.5):\n",
        "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower, upper = q1 - k*iqr, q3 + k*iqr\n",
        "    return (s < lower) | (s > upper)\n",
        "\n",
        "if \"Price\" in df.columns:\n",
        "    df[\"Price_is_outlier\"] = iqr_flags(df[\"Price\"]).astype(int)\n"
      ],
      "metadata": {
        "id": "7seUQQlTSgmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAnd4DSyeHDb"
      },
      "source": [
        "## Univariate Analysis\n",
        "\n",
        "# The distribution of individual variables is explored to understand the overall data structure and identify potential skewness, imbalance or anomalous values.\n",
        "\n",
        "# 1) Bar plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "df[\"Make\"].value_counts().nlargest(20).plot(kind=\"bar\")\n",
        "plt.title(\"Distribution of Make (Top 20 Categories)\")\n",
        "plt.xlabel(\"Make\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2) Histogram\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(df[\"Tenure\"], bins=30)\n",
        "plt.title(\"Distribution of Customer Tenure\")\n",
        "plt.xlabel(\"Tenure\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3) Target variable – Class balance\n",
        "plt.figure(figsize=(4, 3))\n",
        "df[\"Churn\"].value_counts(normalize=True).plot(kind=\"bar\")\n",
        "plt.title(\"Churn Class Distribution\")\n",
        "plt.xlabel(\"Churn\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Bivariate Analysis\n",
        "\n",
        "# Relationships between pairs of variables are explored to identify potential associations with customer churn and to highlight patterns useful for further analysis.\n",
        "\n",
        "# 1) Scatterplot\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.scatterplot(\n",
        "    x=\"Tenure\",\n",
        "    y=\"C1\",\n",
        "    hue=\"Churn\",\n",
        "    data=df,\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title(\"Tenure vs C1 by Churn Status\")\n",
        "plt.xlabel(\"Tenure\")\n",
        "plt.ylabel(\"C1\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 2) Heatmap\n",
        "# Select only numerical features for correlation analysis\n",
        "num_features = df.select_dtypes(include=\"number\")\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(\n",
        "    num_features.corr(),\n",
        "    cmap=\"coolwarm\",\n",
        "    center=0,\n",
        "    annot=False\n",
        ")\n",
        "plt.title(\"Correlation Matrix of Numerical Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v4gn-4m1URkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Bivariate Insights\n",
        "\n",
        "- Tenure shows different distribution patterns between churned and non-churned customers.\n",
        "- Certain numerical features appear moderately correlated, suggesting potential redundancy.\n",
        "- These relationships guide feature selection for subsequent analysis."
      ],
      "metadata": {
        "id": "mR7A6L9mVfHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}